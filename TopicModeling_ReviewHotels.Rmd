---
title: "TopicModeling_ReviewHotels"
author: "Martin Eduardo Espinoza Salomon"
date: "2024-06-10"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Part 2

### Introduction

The objective is to identify the most topics discussed in both positive and negative reviews using topic modeling techniques. The analysis consists of multiple steps, such as data pre-processing, classification of reviews, data transformation including tokenization, topic modelling, and classification of topics.  Furthermore, the three top factors that affect the satisfaction and dissatisfaction of the customers will be discussed. 


```{r}
# libraries
library("dplyr") # basic data manipulation
library("tm") # package for text mining package
library("stringr") # package for dealing with strings
library("RColorBrewer")# package to get special theme color
library("wordcloud") # package to create wordcloud
library("topicmodels") # package for topic modelling
library("ggplot2") # basic data visualization
library("LDAvis") # LDA specific visualization 
library("servr") # interactive support for LDA visualization
library("cld2") # for remove non-english reviews

# functions that will be used:

# this function eliminates reviews that are not in English (Parameters: dataset,
#   and a name of column of the dataset)
eliminate_nonEnglish_words <- function(dataset, nameColumn){
  # detect language
  language <- detect_language(nameColumn)
  language_df <- data.frame(language = language)
  dataset <- cbind(dataset, language_df)
  # filter no english reviews
  english_reviews <- subset(dataset, language == "en")
  non_english_reviews <- subset(dataset, !(language %in% c("en")))
  english_reviews$language <- NULL
  return(english_reviews)
}

# function that create a corpus (Parameters: columname of the dataset)
create_corpus <- function(dataset_nameColumn){
  reviews <- stringr::str_conv(dataset_nameColumn, "UTF-8")
  # create Corpus
  corpus_reviews <- Corpus(VectorSource(reviews))
  return(corpus_reviews)
}

# function that make lemmatization, removal of punctuation, numbers, stopword, 
#     and lowercase all tokens (Parameters: corpus)
clean_reviews <- function(corpus, non_significant_words){
  dtm_reviews <- DocumentTermMatrix(corpus, control = list(
    lemma=TRUE,removePunctuation = TRUE, removeNumbers = TRUE,
    stopwords = TRUE,tolower = TRUE))
   # Remove non-significant words
  dtm_reviews <- dtm_reviews[, !(colnames(dtm_reviews) %in% non_significant_words)]
  raw.sum=apply(dtm_reviews ,1,FUN=sum)
  dtm_reviews = dtm_reviews [raw.sum!=0,]
  return(dtm_reviews)
}

# Function that create DTM with term frequency (Parameter: dtmdocs)
create_DTM_termFrequency <- function(dtmdocs){
  # frequency table
  dtm.new <- as.matrix(dtmdocs)
  frequency <- colSums(dtm.new)
  frequency <- sort(frequency, decreasing=TRUE)
  doc_length <- rowSums(dtm.new)
  #frequency[1:10] 
  #return(frequency)
  return(list(frequency = frequency, dtm.new = dtm.new, doc_length = doc_length))
}

# function that create a wordcloud (Parameters: frequency table)
create_Wordcloud <- function(frequency){
  words <- names(frequency)# get back the word
  wordcloud(words[1:100], frequency[1:100], rot.per=0.15, random.order = FALSE,
            scale=c(4,0.5), random.color = FALSE, colors=brewer.pal(8,"Dark2"))
}

#function that determine the number of topics (Parameters: dtm.new, the initial
#   and the last number of range for topics)
Determining_Number_Topics <- function(dtm.new, initial, final){
  library("ldatuning")
  result <- FindTopicsNumber(dtm.new,
                             topics = seq(from = initial, to = final, by = 1),
  metrics = c("Griffiths2004", "CaoJuan2009", "Arun2010"),
  method = "Gibbs", control = list(seed = 77), mc.cores = 2L, verbose = TRUE)
  #make the plot
  FindTopicsNumber_plot(result)
}


# function that make the Topic Modelling LDA (Parameters: dtm and number of topics)
topic_modelling_LDA <- function(dtm,numberTopics){
  #Topic Modelling: Latent Dirichlet Allocation
  ldaOut <-LDA(dtm,numberTopics,method="Gibbs",control=list(iter=1000,seed=1000))
  phi <- posterior(ldaOut)$terms %>% as.matrix 
  #matrix, with each row containing the distribution over terms for a topic,
  theta <- posterior(ldaOut)$topics %>% as.matrix 
  #matrix, with each row containing the probability distribution over topics
  return(list(ldaOut = ldaOut, phi = phi, theta = theta))
}

# function that group by topics founded (Parameters: dataset, and ldaOutas)
grouping_by_topics <- function(dataset, ldaOut){
  #To get grouping documents by the topics that was found:
  # Which 'topic' is the review in (highest probability)
  ldaOut.topics <- data.frame(topics(ldaOut))
  ldaOut.topics$index <- as.numeric(row.names(ldaOut.topics))
  dataset$index <- as.numeric(row.names(dataset))
  #datawithtopic <- merge(dataset, ldaOut.topics, by='index',all.x=TRUE)
  #datawithtopic <- datawithtopic[order(datawithtopic$index), ]
  #return(datawithtopic)
}

# function that get probabilities (Parameters: ldaOut)
get_table_probabilities <- function(ldaOut){
  #To get grouping documents by the topics that was found for all topics
  # For each review, how closely it associate with each topics
  topicProbabilities <- as.data.frame(ldaOut@gamma)
  topicProbabilities[0:10,1:5]
}

# function that visializing the LDA (Parameters: phi, theta, doc_length,
#   and frequency )
Visualising_LDA <- function(phi, theta, doc_length, frequency){
  # Visualizing with LDAVis
  vocab <- colnames(phi) #vocab list in DTM
  # create the JSON object to feed the visualization in LDAvis:
  json_lda <- createJSON(phi = phi, theta = theta, vocab = vocab, 
                         doc.length = doc_length, term.frequency = frequency)
  serVis(json_lda, out.dir = 'vis', open.browser = TRUE)
}

get_Most_Influenced_topics <- function(ldaOut){
  topic_probabilities<- as.data.frame(posterior(ldaOut)$topics)
  mean_topic_prob <- colMeans(topic_probabilities)
  topic_data <- data.frame(Topic = 1:length(mean_topic_prob),
                           topic_mean = mean_topic_prob)
  topic_data <- topic_data[order(topic_data$topic_mean, decreasing = TRUE), ]
  return(topic_data)
  }

```


### Classify Positive and Negative Reviews

Data exploration was carried out for the reviews dataset to observe its structure. It was observed that there are 2 columns in the dataset, one is the level of satisfaction (number from 1 to 5 where the closest to five means greater satisfaction and the closer to 1 means greater dissatisfaction), and the other is the description of the review. Additionally, it was noted that there are $10000$ reviews in total, and the reviews are in different languages. For this analysis, only reviews in English will be used, so all reviews that are in a non-English language will be eliminated. In order to eliminate them, the $cld2$ library was used, which detects the language and classifies them according to their language, and then simply used the English classification, so the others were eliminated from the dataset. Once the English reviews were obtained, it was proceeded to adjust the seed to $449$ to obtain a sample of $2000$ reviews.

Afterwards, The sample was then divided into two as satisfactory reviews and unsatisfactory reviews. In this division, reviews with a satisfaction level of 1 and 2 were used to classify unsatisfactory reviews. On the other hand, satisfaction levels 5 and 4 were used to classify satisfactory reviews. This criterion was used because to obtain the best customer satisfaction, levels 5 and 4 are the highest to obtain it. On the other hand, level 1 and 2 are the lowest levels of satisfaction, therefore indicating dissatisfaction. A total of $1496$ satisfactory reviews (positive) and a total of $227$ unsatisfactory reviews (negative) were obtained. Furthermore, Level 3 of satisfaction was omitted because it is a neutral state between satisfaction and dissatisfaction, in addition, at this level there are a total of $277$ reviews. Comparing the number of reviews of level 3 with the reviews already classified as dissatisfaction, it can be seen that the number of reviews of level 3 are greater than the union of level 1 and 2, so if this level is considered dissatisfaction, it would directly affect the results because levels 1 and 2 would not be as influential as they would be without using level 3.


```{r}
# read the data
full_data_hotels <- read.csv("HotelsData.csv")
# eliminate non-english words
english_reviews <- eliminate_nonEnglish_words(full_data_hotels,
                                              full_data_hotels$Text.1)
# get my sample
set.seed(449)
data_reviews <- sample_n(english_reviews, 2000)

# split the reviews
data_reviews_pos <- subset(data_reviews, Review.score == 5 | Review.score == 4)
data_reviews_neg <- subset(data_reviews, Review.score == 1 | Review.score == 2)
```


The next step was to create a corpus of positive reviews and another of negative reviews; These two corpus were responsible for collecting the reviews. Tokenization was then used to separate the words and a frequency document term matrix was created for positive and negative reviews. In order to get a good topic model, the words contained in the reviews should be cleaned for better prediction. In this matrix, word cleaning was performed, punctuation, stop words and numbers were removed, lemmatization was performed to group similar tokens and all tokens were converted to lowercase. Subsequently, two frequency tables were created, one for satisfactory reviews and another for unsatisfactory reviews. These tables show the frequency of each word in the reviews. With these frequency tables, it can be created Wordcloud graphs to visualize the most repeated words for both positive and negative reviews.


```{r echo=FALSE, include = TRUE, fig.width=6, fig.height=4}
non_significant_words <- c("hotel", "room", "london", "rooms", "one", "just", "really", "get", "hotels", "stay")

# create corpus Positive reviews
corpus_reviews_pos <- create_corpus(data_reviews_pos$Text.1)
# clean Positive reviews
dtm_reviews_pos <- clean_reviews(corpus_reviews_pos, non_significant_words)
# create DTM with Positive frecuency
DTM_results_pos <- create_DTM_termFrequency(dtm_reviews_pos)
frequency_pos <- DTM_results_pos$frequency
dtm.new_pos <- DTM_results_pos$dtm.new
doc_length_pos <- DTM_results_pos$doc_length
# Positive Wordcloud
create_Wordcloud(frequency_pos)
mtext("Figure 7: Words most used fo Satisfactory Reviews (Positive)", side = 1,
      line = 4.3)
```

It can be seen in Figure 7 that some of the most repeated words for positive reviews are “staff”, “clean”, “service”, and “comfortable”. This diagram illustrates what customers consider a  positive review. In contrast, Figure 8 shows what consumers consider a negative review, such as the words "reception", "small", "hot", "bed", indicating that customers may have had problems with the reception, or that the room or the bed were small, indicating that they were dissatisfied for any of these possible reasons.


```{r echo=FALSE, include = TRUE, fig.width=6, fig.height=4}
# create corpus reviews
corpus_reviews_neg <- create_corpus(data_reviews_neg$Text.1)
# clean reviews
dtm_reviews_neg <- clean_reviews(corpus_reviews_neg, non_significant_words)
# create DTM with frecuency
DTM_results_neg <- create_DTM_termFrequency(dtm_reviews_neg)
frequency_neg <- DTM_results_neg$frequency
dtm.new_neg <- DTM_results_neg$dtm.new
doc_length_neg <- DTM_results_neg$doc_length
# Wordcloud
create_Wordcloud(frequency_neg)
mtext("Figure 8: Words most used for Dissatisfaction Reviews (Negative)",
      side = 1, line = 4.3)
```

### Topic Modelling

The next step is to develop a topic modelling for both positive and negative reviews. Using words from reviews, this topic modeling is responsible for predicting the probability that a word is associated with a topic. To do this, first, the number of topics will be chosen for both positive and negative reviews. The $ldatuning$ library will be used, which has an algorithm to decide the number of topics. This algorithm will be represented in a graph.


```{r echo=FALSE, include = TRUE}
# determing the number of topics
Determining_Number_Topics(dtm.new_pos, 5, 20)
Determining_Number_Topics(dtm.new_neg, 5, 20)
```


In order to decide the optimal number of topics for reviews using Figures 9 and 10, the aim is to choose the minimum value for the Arun2010 and CaoJuan2009 criteria, and the maximum value for the Griffiths2004 criterion. A range of topics between 5 and 20 was chosen and from these values an optimal number was chosen using the criteria mentioned above. It can be seen in Figure 9 of the positive reviews that the optimal value is $19$, and for Figure 10 of the negative reviews that the optimal value is $14$. These values represent the number of optimal topics to use in topic modeling.

The next step is to develop topic modeling. For this, the Latent Dirichlet Allocation (LDA) function will be used. Basically this function is responsible for dividing all the reviews into the number of optimal topics that were previously obtained. This division is based on the similarity of the words in the reviews, so similar words are grouped into topics. In addition, the frequency and probabilities of each word for each topic are obtained, which allows evaluating the relevance of each topic.

Following, the average probability of each topic in the entire corpus was calculated and the topics were ordered based on these average probabilities from highest to lowest. Firstly, for positive reviews it was found that the top three of the most relevant topics were 16, 14 and 8. On the other hand, for negative reviews it was found that the top three of the most relevant topics were 2, 5 and 14. These topics with their respective most frequent words can be seen in Tables 3 and 4 for positive and negative reviews respectively.


```{r}
# Modelling LDA Positive
number_of_topics_pos=19
Modelling_results_pos <-topic_modelling_LDA(dtm_reviews_pos,number_of_topics_pos)
ldaOut_pos <- Modelling_results_pos$ldaOut
phi_pos <- Modelling_results_pos$phi
theta_pos<- Modelling_results_pos$theta

# generate a list of  topics Which highest alpha 'term' is part of which topics
ldaOut.terms_pos <- as.matrix(terms(ldaOut_pos, 15))

# make the grouping fot Positive
grouping_by_topics(data_reviews_pos,ldaOut_pos)

# get the most influenced topics in order Positive
topics_influenced_pos <- get_Most_Influenced_topics(ldaOut_pos)
write.csv(ldaOut.terms_pos, "ldaOut_terms_pos.csv", row.names = TRUE)
#print(ldaOut.terms_pos)

# Visualizing with Positive LDAVis
Visualising_LDA(phi_pos, theta_pos, doc_length_pos, frequency_pos)
```


### Top factors that affect the satisfaction and dissatisfaction of the customers

When analyzing the three main factors that affect customer satisfaction, using the words in Table 3, it can be seen that:

* Topic 16: It seems to be mainly about the location of the hotel and its accessibility via public transport, it is suggested that guests are satisfied about how convenient the hotel is in terms of its proximity to public transport stations, bus stops, and parks.

* Topic 14: It seems that the main topic focuses on the overall experience of staying at the hotel, with a focus on the quality of service and facilities. The hospitality of the staff, the cleanliness of the rooms, the comfort of the facilities, and the general experience of being in the hotel are the factors that satisfy customers.

* Topic 8: It appears to focus on the hotel accommodation experience, with an emphasis on the location of the hotel and its suitability for families with children. Furthermore, customers are happy about the convenience of the hotel's location, as well as its suitability for families with children.


```{r}
# Modelling LDA Negative
number_of_topics_neg=14
Modelling_results_neg <-topic_modelling_LDA(dtm_reviews_neg,number_of_topics_neg)
ldaOut_neg <- Modelling_results_neg$ldaOut
phi_neg <- Modelling_results_neg$phi
theta_neg<- Modelling_results_neg$theta

# generate a list of  topics Which highest alpha 'term' is part of which topics
ldaOut.terms_neg <- as.matrix(terms(ldaOut_neg, 15))

# make the grouping fot Negative
grouping_by_topics(data_reviews_neg,ldaOut_neg)

# get the most influenced topics in order Negative
topics_influenced_neg <- get_Most_Influenced_topics(ldaOut_neg)
write.csv(ldaOut.terms_neg, "ldaOut_terms_neg.csv", row.names = TRUE)
#print(ldaOut.terms_neg)

# Visualizing with Negative LDAVis
Visualising_LDA(phi_neg, theta_neg, doc_length_neg, frequency_neg)
```

Following, when analyzing the three main factors that affect customer dissatisfaction, using the words in Table 4, It seems that:

* Topic 2: Reviews seem to mainly express discontent with the small size of the rooms. They might also express dissatisfaction if staff service was not up to expectations or if the availability of restaurants in or around the hotel was unsatisfactory. Additionally, the location of the hotel appears not to be located near public transportation stations or tourist attractions.

* Topic 5: The main topic appears to be dissatisfaction with the hotel's room infrastructure and facilities, with specific complaints relating to the bed, shower and bathroom, as well as the overall quality of the rooms. These complaints may be about uncomfortable beds, shabby bathrooms, small rooms, thin walls that don't provide privacy,  problems with windows or doors, and possible heating problems.

* Topic 14: Reviews point out that the breakfast was unsatisfactory which made for an unsatisfactory stay for the guests. Sleep quality is another concern, and this could be caused by things like insufficient illumination, noise from outside, or an absence of facilities in the room. In addition, the hotel's surroundings and the cost in comparison to the quality and services offered might not be desirable.


### Conclusion

In summary, by analyzing the reviews, the three main factors that influence customer satisfaction and dissatisfaction were identified, where it was found that positive reviews highlight the convenient location and quality of service, while negative reviews focus on problems with the facilities and breakfast. This analysis allows the hotel to continue offering a good service based on the satisfactory reviews found, and at the same time, improve those aspects that customers find unsatisfactory in order to offer a better service.





